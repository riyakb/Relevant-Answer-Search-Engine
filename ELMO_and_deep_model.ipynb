{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ELMO_and_deep_model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/riyakb/Relevant-Answer-Search-Engine/blob/master/ELMO_and_deep_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "Wi20W2A6Zi2D",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.utils import np_utils\n",
        "from keras.models import Model\n",
        "\n",
        "activation_fn = 'elu'\n",
        "\n",
        "########################### DEFINE YOUR DL MODEL HERE ############################################\n",
        "\n",
        "def nn_model(query_input_len, answer_input_len, batch_size):\n",
        "  ############### for query input #########################\n",
        "  \n",
        "  layer1_1 = keras.layers.Input(shape=(query_input_len, embedding_dim, 1))\n",
        "  conv1_1 = keras.layers.convolutional.Conv2D(32, (2, 5), activation=activation_fn)(layer1_1)\n",
        "  pool1_1 = keras.layers.convolutional.AveragePooling2D()(conv1_1)\n",
        "  conv1_2 = keras.layers.convolutional.Conv2D(32, (2, 5), activation=activation_fn)(pool1_1)\n",
        "  pool1_2 = keras.layers.convolutional.AveragePooling2D()(conv1_2)\n",
        "  flat1_1 = keras.layers.Flatten()(pool1_2)\n",
        "  drop1_1 = keras.layers.Dropout(0.24)(flat1_1)\n",
        "  dense1_1 = keras.layers.Dense(800, activation=activation_fn)(drop1_1)\n",
        "  drop1_2 = keras.layers.Dropout(0.28)(dense1_1)\n",
        "  dense1_2 = keras.layers.Dense(500, activation=activation_fn)(drop1_1)\n",
        "  drop1_3 = keras.layers.Dropout(0.25)(dense1_2)\n",
        "  \n",
        "  \n",
        "  ############### For answers input #######################\n",
        "\n",
        "  layer2_1 = keras.layers.Input(shape=(answer_input_len, embedding_dim, 1))\n",
        "  conv2_1 = keras.layers.convolutional.Conv2D(32, (2, 5), activation=activation_fn)(layer2_1)\n",
        "  pool2_1 = keras.layers.convolutional.AveragePooling2D()(conv2_1)\n",
        "  conv2_2 = keras.layers.convolutional.Conv2D(32, (2, 5), activation=activation_fn)(pool2_1)\n",
        "  pool2_2 = keras.layers.convolutional.AveragePooling2D()(conv2_2)\n",
        "  conv2_2 = keras.layers.convolutional.Conv2D(32, (2, 5), activation=activation_fn)(pool2_2)\n",
        "  pool2_3 = keras.layers.convolutional.AveragePooling2D()(conv2_2)\n",
        "  flat2_1 = keras.layers.Flatten()(pool2_3)\n",
        "  drop2_1 = keras.layers.Dropout(0.1)(flat2_1)\n",
        "  dense2_1 = keras.layers.Dense(3000, activation=activation_fn)(drop2_1)\n",
        "  drop2_2 = keras.layers.Dropout(0.3)(dense2_1)\n",
        "  dense2_2 = keras.layers.Dense(1500, activation=activation_fn)(drop2_2)\n",
        "  drop2_3 = keras.layers.Dropout(0.2)(dense2_2)\n",
        "  dense2_3 = keras.layers.Dense(500, activation=activation_fn)(drop2_3)\n",
        "  drop2_4 = keras.layers.Dropout(0.2)(dense2_3)\n",
        "#   dense2_4 = keras.layers.Dense(500, activation=activation_fn)(drop2_4)\n",
        "#   drop2_5 = keras.layers.Dropout(0.2)(dense2_4)\n",
        "#   dense2_5 = keras.layers.Dense(200, activation=activation_fn)(drop2_5)\n",
        "#   drop2_6 = keras.layers.Dropout(0.2)(dense2_5)\n",
        "  \n",
        "  ############## Final merge of 2 models ##################\n",
        "  \n",
        "  merge = keras.layers.multiply([drop1_3, drop2_4])\n",
        "  \n",
        "  final_l1 = keras.layers.Dense(200, activation=activation_fn)(merge)\n",
        "#   final_l2 = keras.layers.Dense(100, activation=activation_fn)(final_l1)\n",
        "  final_l3 = keras.layers.Dense(10, activation=activation_fn)(final_l1)\n",
        "  final = keras.layers.Dense(1, activation='sigmoid')(final_l3)\n",
        "  \n",
        "  final_model = Model(inputs=[layer1_1, layer2_1], outputs=final)\n",
        "  \n",
        "  return final_model\n",
        "\n",
        "##################################################################################################"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WL-RvHHqZtoC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "model = nn_model(max_query_len, max_answer_len, batch_size)\n",
        "model.compile('Adadelta', 'binary_crossentropy')\n",
        "\n",
        "count=0\n",
        "break_point = 500\n",
        "\n",
        "for  data in pd.read_csv('rish_data.tsv', sep='\\t', chunksize=batch_size, names=['id', 'query', 'answers', 'correct answer', 'count']):\n",
        "   \n",
        "  count+=1\n",
        "  \n",
        "  query_Train = convert_data(data['query'], max_query_len)\n",
        "  answer_Train = convert_data(data['answers'], max_answer_len)\n",
        "  yTrain = data['correct answer']\n",
        "  \n",
        "#   print(query_Train.shape)\n",
        "#   print(answer_Train.shape)\n",
        "   \n",
        "#   print(X['query'][0].shape)\n",
        "#   print(X['answers'].shape)\n",
        "  \n",
        "  query_Train = query_Train.reshape(batch_size, max_query_len, embedding_dim, 1)\n",
        "  answer_Train = answer_Train.reshape(batch_size, max_answer_len, embedding_dim, 1)\n",
        "  \n",
        "  ################### Training code over here, and function to save model also. Pickle library already imported ###################\n",
        "  \n",
        "  history = model.fit([query_Train, answer_Train], yTrain, validation_split=0.2, verbose=0, epochs=18)\n",
        "  \n",
        "  model.save(\"cnn_Model_1.h5\")\n",
        "  print(count)\n",
        "    \n",
        "  ########################################################################\n",
        "  \n",
        "# model.save(\"cnn_Model_\"+str(count)+\".h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aNOPRFxLZyKQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# history.history\n",
        "\n",
        "plt.plot(history.history['loss'], label = \"Training Loss\")\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zGTrCN2lZ7xR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install allennlp\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
        "# from allennlp.commands.elmo import ElmoEmbedder\n",
        "# elmo = ElmoEmbedder()\n",
        "\n",
        "# dssm_scores = np.load('dssm_scores.npy')\n",
        "# cdssm_scores = np.load('cdssm_scores.npy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8b7sUWbIZ_gO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "q_embed_save = np.load('q_embedding.npy')\n",
        "a_embed_save = np.load('a_embedding.npy')\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "init = tf.initialize_all_variables()\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "count=0\n",
        "\n",
        "firstRun=True\n",
        "\n",
        "# q_embed_save=np.empty([0,0,0])\n",
        "# a_embed_save=np.empty([0,0,0])\n",
        "\n",
        "print('Starting execution of for loop')\n",
        "\n",
        "for data in pd.read_csv(\"reduced_data.tsv\", sep='\\t', chunksize=100, names=['id', 'query', 'answers', 'correct answer', 'count']):\n",
        "  data = data.reset_index()\n",
        "  if data['index'][0]>100000:\n",
        "    break\n",
        "  elif q_embed_save.shape[0]>data['index'][0]:\n",
        "    count=q_embed_save.shape[0]/100\n",
        "    print(count)\n",
        "    pass\n",
        "  else:\n",
        "#     q = []\n",
        "#     a = []\n",
        "#     for j in range(data.shape[0]):\n",
        "#       q.append(\" \".join(convert_string(data['query'][j])))\n",
        "#       a.append(\" \".join(convert_string(data['answers'][j])))\n",
        "    q_embed = elmo(data['query'].tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "    a_embed = elmo(data['answers'].tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
        "\n",
        "    q_embed=sess.run(q_embed)\n",
        "    a_embed=sess.run(a_embed)\n",
        "\n",
        "    y_train = data['correct answer']\n",
        "\n",
        "    q_embed_2 = pad_sequences(q_embed, maxlen = 20)\n",
        "    a_embed_2 = pad_sequences(a_embed, maxlen = 150)\n",
        "\n",
        "    if count==0:\n",
        "      q_embed_save=np.copy(q_embed_2)\n",
        "      a_embed_save=np.copy(a_embed_2)\n",
        "\n",
        "    q_embed_save = np.vstack((q_embed_save, q_embed_2))\n",
        "    a_embed_save = np.vstack((a_embed_save, a_embed_2))\n",
        "\n",
        "  #   print(q_embed_2.shape)\n",
        "  #   print(a_embed_2.shape)\n",
        "  #   print(np.append(q_embed, a_embed, axis=0).shape)\n",
        "    \n",
        "    if count%20==0:\n",
        "      np.save(\"q_embedding.npy\", q_embed_save)\n",
        "      np.save(\"a_embedding.npy\", a_embed_save)\n",
        "      print(count)\n",
        "    count+=1\n",
        "    \n",
        "    \n",
        "#     break\n",
        "\n",
        "# print(np.vstack((q_embed_2, a_embed_2)).shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}